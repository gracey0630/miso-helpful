{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee68aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49144fb",
   "metadata": {},
   "source": [
    "## cooking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2f8321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open('cooking methods.pdf') as pdf:\n",
    "    for page in pdf.pages:\n",
    "        tables = page.extract_tables()\n",
    "        \n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                # Convert to DataFrame without assuming first row is header\n",
    "                repl = {\"\\n\": \"\", \"\\uf0b7\": \"\"}\n",
    "                # print(table)\n",
    "                table = [[txt.replace(\"\\n\", \" \").replace(\"\\uf0b7\", \" \") if txt is not None else txt \n",
    "                            for txt in tbl] \n",
    "                            for tbl in table\n",
    "                        ]\n",
    "                df = pd.DataFrame(table)\n",
    "                all_tables.append(df)\n",
    "\n",
    "# Stack all tables vertically, ignore column mismatches\n",
    "combined_df = pd.concat(all_tables, ignore_index=True, sort=False)\n",
    "combined_df = combined_df.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0b1da1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left shift for weird ocr extraction\n",
    "combined_df[2] = combined_df[2].fillna(combined_df[3])\n",
    "combined_df[3] = combined_df[3].fillna(combined_df[4])\n",
    "combined_df.drop(4, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "84affbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare header\n",
    "combined_df.columns = [\"COOKING METHODS\", \"DESCRIPTION\", \"MERITS\", \"DEMERITS\"]\n",
    "combined_df = combined_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "45a363b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine rows that were separated by a page\n",
    "combined_df = combined_df.fillna('')\n",
    "rows_to_be_combined = list(combined_df[combined_df[\"COOKING METHODS\"] == ''].index)\n",
    "for row in rows_to_be_combined:\n",
    "    for col in combined_df.columns:\n",
    "        combined_df.loc[row - 1, col] =  (combined_df.loc[row - 1, col] + combined_df.loc[row, col]).strip()\n",
    "combined_df = combined_df.drop(rows_to_be_combined, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2a5e3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add type of method column\n",
    "type_of_method_idx = list(combined_df[combined_df[\"DESCRIPTION\"] == ''].index)\n",
    "type_of_method_idx_mask = combined_df.index.isin(type_of_method_idx)\n",
    "combined_df['TYPE OF METHOD'] = combined_df.loc[type_of_method_idx_mask, 'COOKING METHODS']\n",
    "combined_df['TYPE OF METHOD'] = combined_df['TYPE OF METHOD'].ffill()\n",
    "combined_df = combined_df.drop(type_of_method_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "98c20694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "combined_df.to_csv(\"cooking_methods.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b5a74",
   "metadata": {},
   "source": [
    "## fundamentals of cooking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2e10d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ingredients(df):\n",
    "\n",
    "    recipe = {\n",
    "        'dish_name': df.iloc[0, 1].replace(\"\\n\", \" \"),\n",
    "        'prep_time': df.iloc[0, 2].replace(\"\\n\", \" \"),\n",
    "        'cooking_time': df.iloc[0, 3].replace(\"\\n\", \" \"),\n",
    "        'portions': df.iloc[1, 1],\n",
    "        'unit_size': df.iloc[1, 3],\n",
    "        'ingredients': []\n",
    "    }\n",
    "\n",
    "    # Find ingredients table\n",
    "    items_row = df[df.iloc[:, 0] == 'Items'].index\n",
    "    if len(items_row) > 0:\n",
    "        table_start = items_row[0] + 1\n",
    "        \n",
    "        # Find where ingredint entries starts\n",
    "        df = df.iloc[table_start:, :].replace('', np.nan).dropna(subset=[0,2])\n",
    "        df.columns = range(len(df.columns))\n",
    "        \n",
    "\n",
    "        # Add ingredients\n",
    "        for _, row in df.iterrows():\n",
    "            recipe['ingredients'].append({\n",
    "                'item': row[0].replace(\"\\n\", \" \").replace(\"\\\\\", \" \"),\n",
    "                'quantity': row[1].replace(\"\\n\", \" \").replace(\"\\\\\", \" \")\n",
    "            })\n",
    "            recipe['ingredients'].append({\n",
    "                'item': row[2].replace(\"\\n\", \" \").replace(\"\\\\\", \" \"),\n",
    "                'quantity': row[3].replace(\"\\n\", \" \").replace(\"\\\\\", \" \")\n",
    "            })\n",
    "\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5968eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    res = pd.DataFrame()\n",
    "\n",
    "    col_idx = 0\n",
    "    for i in range(0, len(df.columns), 2):\n",
    "        if i + 1 < len(df.columns):\n",
    "            # fill nan in first col with vals from second col\n",
    "            res[col_idx] = df.iloc[:, i].fillna(df.iloc[:, i + 1]).str.replace(\"\\n\", \" \").tolist()\n",
    "        col_idx+=1\n",
    "    \n",
    "    # reset col names\n",
    "    res.columns = res.iloc[0,:]\n",
    "    res = res[1:]\n",
    "\n",
    "    # res_json = {}\n",
    "\n",
    "    # display(res) \n",
    "\n",
    "    # if res.iloc[0,0] == \"Staples\" or res.iloc[0,0] == \"Sauce\":\n",
    "    #     print(\"in if\")\n",
    "    #     for _, row in res.itterows():\n",
    "    #         key = row.iloc[0]\n",
    "    #         val = row.iloc[1:].tolist()\n",
    "    #         res_json[key] = val\n",
    "    # else:\n",
    "    #     print(\"in else\")\n",
    "    #     for col in res.columns:\n",
    "    #         key = res.iloc[0, col].replace(\"\\n\", \" \")  # First row value as key\n",
    "    #         val = res.iloc[1:, col].str.replace(\"\\n\", \" \").tolist()  # Remaining rows as list\n",
    "    #         res_json[key] = val\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f7e1e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_table(table, i):\n",
    "\n",
    "    df = (pd.DataFrame(table)\n",
    "        .map(lambda x: np.nan if x in [\"\", None] else x)\n",
    "        .dropna(how=\"all\", axis=0)\n",
    "        .dropna(how=\"all\", axis=1))\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.columns = range(len(df.columns))\n",
    "    \n",
    "    if df.shape == (1,1) and df.iloc[0, 0]:\n",
    "        return\n",
    "\n",
    "    # template one: recipe ingredient\n",
    "    if df.iloc[0,0] == \"Name of dish\":\n",
    "        res = extract_ingredients(df)\n",
    "        # result is json\n",
    "        dish_name = res[\"dish_name\"].replace(\" \", \"_\")\n",
    "        with open(f\"foc/foc_ingredients_{dish_name}.json\", \"w\") as f:\n",
    "            json.dump(res, f, indent=2, ensure_ascii=False)\n",
    "        return\n",
    "\n",
    "    # template two: 2 lists\n",
    "    elif pd.isna(df.iloc[0, 0]) and pd.isna(df.iloc[1, 1]):\n",
    "        res = get_info(df)\n",
    "        res.to_csv(f\"foc/foc_table_{i}.csv\")\n",
    "        return\n",
    "\n",
    "    # rest will be considered in text\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d5a28110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_text(text):\n",
    "    # Remove page headers like \"1FUNDAMENTALS OF COOKING\", \"2FUNDAMENTALS OF COOKING\", etc.\n",
    "    text = re.sub(r'^\\d+FUNDAMENTALS OF COOKING\\s*$', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Check if there's a Glossary section\n",
    "    glossary_match = re.search(r'\\bGlossary\\b', text, re.IGNORECASE)\n",
    "    \n",
    "    # Match section numbers\n",
    "    pattern = r'(\\d+(?:\\.\\d+)+)([^\\n]+)'\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    \n",
    "    # Keywords to stop content extraction\n",
    "    stop_keywords = r'\\b(Exercise|Activity|Teacher\\'s guide|Glossary)\\b'\n",
    "    \n",
    "    sections = {}\n",
    "    \n",
    "    # Extract numbered sections\n",
    "    for i, match in enumerate(matches):\n",
    "        section_title = match.group(2).strip()\n",
    "        start = match.end()\n",
    "        \n",
    "        # Determine end position\n",
    "        if i + 1 < len(matches):\n",
    "            end = matches[i + 1].start()\n",
    "        else:\n",
    "            end = len(text)\n",
    "        \n",
    "        # Get initial content\n",
    "        content = text[start:end]\n",
    "        \n",
    "        # Find first occurrence of stop keyword\n",
    "        stop_match = re.search(stop_keywords, content, re.IGNORECASE)\n",
    "        if stop_match:\n",
    "            content = content[:stop_match.start()]\n",
    "        \n",
    "        # Clean up content\n",
    "        content = content.strip()\n",
    "        content = content.replace('\\n', ' ')\n",
    "        content = re.sub(r' {2,}', ' ', content)\n",
    "        \n",
    "        if content:\n",
    "            sections[section_title] = content\n",
    "    \n",
    "    # Extract glossary if it exists\n",
    "    if glossary_match:\n",
    "        glossary_text = text[glossary_match.end():].strip()\n",
    "        glossary_pattern = r'([A-Z][A-Za-z\\s]+?)\\s*[--]\\s*((?:(?![A-Z][a-z]+\\s*[--]).)+)'\n",
    "        \n",
    "        glossary = {}\n",
    "        \n",
    "        for match in re.finditer(glossary_pattern, glossary_text, re.DOTALL):\n",
    "            term = match.group(1).strip()\n",
    "            definition = match.group(2).strip()\n",
    "            \n",
    "            # Clean up definition\n",
    "            definition = definition.replace('\\n', ' ')\n",
    "            definition = re.sub(r' {2,}', ' ', definition)\n",
    "            \n",
    "            glossary[term] = definition\n",
    "        \n",
    "        if glossary:\n",
    "            sections['Glossary'] = glossary\n",
    "    \n",
    "    with open(\"foc/foc_sections.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(sections, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e87b8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = []\n",
    "all_text = \"\"\n",
    "\n",
    "with pdfplumber.open('FundamentalsofCooking10.pdf') as pdf:\n",
    "    i = 0\n",
    "    for page in pdf.pages:\n",
    "        tables = page.extract_tables()\n",
    "        \n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                handle_table(table, i)\n",
    "                i+=1\n",
    "\n",
    "        text = page.extract_text()\n",
    "\n",
    "        if \" \".join(text.split()[:3]) != \"FUNDAMENTALS OF COOKING\":\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            all_text = all_text + text\n",
    "\n",
    "    # saves section json\n",
    "    handle_text(all_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coms4995 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
